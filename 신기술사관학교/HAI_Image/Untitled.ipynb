{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import imread, imresize, imsave\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import h5py\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, ZeroPadding2D, AveragePooling2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--image_size IMG_SIZE]\n",
      "                             [--content_weight CONTENT_WEIGHT]\n",
      "                             [--style_weight STYLE_WEIGHT]\n",
      "                             [--style_scale STYLE_SCALE]\n",
      "                             [--total_variation_weight TV_WEIGHT]\n",
      "                             [--num_iter NUM_ITER]\n",
      "                             [--rescale_image RESCALE_IMAGE]\n",
      "                             [--rescale_method RESCALE_METHOD]\n",
      "                             [--maintain_aspect_ratio MAINTAIN_ASPECT_RATIO]\n",
      "                             [--content_layer CONTENT_LAYER]\n",
      "                             [--init_image INIT_IMAGE] [--pool_type POOL]\n",
      "                             [--g_max G_MAX] [--g_min G_MIN] [--gamma GAMMA]\n",
      "                             base ref res_prefix\n",
      "ipykernel_launcher.py: error: the following arguments are required: ref, res_prefix\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnorfati/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Neural style transfer with Keras.')\n",
    "parser.add_argument('base_image_path', metavar='base', type=str,\n",
    "                    help='Path to the image to transform.')\n",
    "parser.add_argument('style_reference_image_path', metavar='ref', type=str,\n",
    "                    help='Path to the style reference image.')\n",
    "parser.add_argument('result_prefix', metavar='res_prefix', type=str,\n",
    "                    help='Prefix for the saved results.')\n",
    "\n",
    "parser.add_argument(\"--image_size\", dest=\"img_size\", default=512, type=int, help='Output Image size')\n",
    "parser.add_argument(\"--content_weight\", dest=\"content_weight\", default=0.5, type=float, help=\"Weight of content\") # 0.025\n",
    "parser.add_argument(\"--style_weight\", dest=\"style_weight\", default=0.5, type=float, help=\"Weight of content\") # 1.0\n",
    "parser.add_argument(\"--style_scale\", dest=\"style_scale\", default=1.0, type=float, help=\"Scale the weightage of the style\") # 1, 0.5, 2\n",
    "parser.add_argument(\"--total_variation_weight\", dest=\"tv_weight\", default=1e-5, type=float, help=\"Total Variation in the Weights\") # 1.0\n",
    "parser.add_argument(\"--num_iter\", dest=\"num_iter\", default=10, type=int, help=\"Number of iterations\")\n",
    "parser.add_argument(\"--rescale_image\", dest=\"rescale_image\", default=\"True\", type=str, help=\"Rescale image after execution to original dimentions\")\n",
    "parser.add_argument(\"--rescale_method\", dest=\"rescale_method\", default=\"bilinear\", type=str, help=\"Rescale image algorithm\")\n",
    "parser.add_argument(\"--maintain_aspect_ratio\", dest=\"maintain_aspect_ratio\", default=\"True\", type=str, help=\"Maintain aspect ratio of image\")\n",
    "parser.add_argument(\"--content_layer\", dest=\"content_layer\", default=\"conv5_2\", type=str, help=\"Optional 'conv4_2'\")\n",
    "parser.add_argument(\"--init_image\", dest=\"init_image\", default=\"content\", type=str, help=\"Initial image used to generate the final image. Options are 'content' or 'noise\")\n",
    "parser.add_argument(\"--pool_type\", dest=\"pool\", default=\"max\", type=str, help='Pooling type. Can be \"ave\" for average pooling or \"max\" for max pooling ')\n",
    "parser.add_argument(\"--g_max\", type=float, default=5, help='Clamp - nax')\n",
    "parser.add_argument(\"--g_min\", type=float, default=0.7, help='Clamp - min')\n",
    "parser.add_argument(\"--gamma\", type=int, default=100, help='Gamma weight')\n",
    "\n",
    "args = parser.parse_args()\n",
    "base_image_path = args.base_image_path\n",
    "style_reference_image_path = args.style_reference_image_path\n",
    "result_prefix = args.result_prefix\n",
    "weights_path = r\"vgg16_weights.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def strToBool(v):\n",
    "    return v.lower() in (\"true\", \"yes\", \"t\", \"1\")\n",
    "\n",
    "rescale_image = strToBool(args.rescale_image)\n",
    "maintain_aspect_ratio = strToBool(args.maintain_aspect_ratio)\n",
    "\n",
    "# these are the weights of the different loss components\n",
    "total_variation_weight = args.tv_weight\n",
    "\n",
    "# dimensions of the generated picture.\n",
    "img_width = img_height = args.img_size\n",
    "assert img_height == img_width, 'Due to the use of the Gram matrix, width and height must match.'\n",
    "\n",
    "img_WIDTH = img_HEIGHT = 0\n",
    "aspect_ratio = 0\n",
    "g_max = float(args.g_max)\n",
    "g_min = float(args.g_min)\n",
    "\n",
    "# util function to open, resize and format pictures into appropriate tensors\n",
    "def preprocess_image(image_path, load_dims=False):\n",
    "    global img_WIDTH, img_HEIGHT, aspect_ratio\n",
    "\n",
    "    img = imread(image_path, mode=\"RGB\") # Prevents crashes due to PNG images (ARGB)\n",
    "    if load_dims:\n",
    "        img_WIDTH = img.shape[0]\n",
    "        img_HEIGHT = img.shape[1]\n",
    "        aspect_ratio = img_HEIGHT / img_WIDTH\n",
    "\n",
    "    img = imresize(img, (img_width, img_height))\n",
    "    img = img[:, :, ::-1].astype('float64')\n",
    "    img[:, :, 0] -= 103.939\n",
    "    img[:, :, 1] -= 116.779\n",
    "    img[:, :, 2] -= 123.68\n",
    "    img = img.transpose((2, 0, 1))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    x = x.transpose((1, 2, 0))\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "# Decide pooling function\n",
    "pooltype = str(args.pool).lower()\n",
    "assert pooltype in [\"ave\", \"max\"], 'Pooling argument is wrong. Needs to be either \"ave\" or \"max\".'\n",
    "\n",
    "pooltype = 1 if pooltype == \"ave\" else 0\n",
    "\n",
    "def pooling_func():\n",
    "    if pooltype == 1:\n",
    "        return AveragePooling2D((2, 2), strides=(2, 2))\n",
    "    else:\n",
    "        return MaxPooling2D((2, 2), strides=(2, 2))\n",
    "\n",
    "# get tensor representations of our images\n",
    "base_image = K.variable(preprocess_image(base_image_path, True))\n",
    "style_reference_image = K.variable(preprocess_image(style_reference_image_path))\n",
    "\n",
    "# this will contain our generated image\n",
    "combination_image = K.placeholder((1, 3, img_width, img_height))\n",
    "\n",
    "# combine the 3 images into a single Keras tensor\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)\n",
    "\n",
    "# build the VGG16 network with our 3 images as input\n",
    "first_layer = ZeroPadding2D((1, 1))\n",
    "first_layer.set_input(input_tensor, shape=(3, 3, img_width, img_height))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(first_layer)\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(pooling_func())\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "model.add(pooling_func())\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "model.add(pooling_func())\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(pooling_func())\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "model.add(pooling_func())\n",
    "\n",
    "# load the weights of the VGG16 networks\n",
    "# (trained on ImageNet, won the ILSVRC competition in 2014)\n",
    "# note: when there is a complete match between your model definition\n",
    "# and your weight savefile, you can simply call model.load_weights(filename)\n",
    "assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "f = h5py.File(weights_path)\n",
    "for k in range(f.attrs['nb_layers']):\n",
    "    if k >= len(model.layers):\n",
    "        # we don't look at the last (fully-connected) layers in the savefile\n",
    "        break\n",
    "    g = f['layer_{}'.format(k)]\n",
    "    weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "    model.layers[k].set_weights(weights)\n",
    "f.close()\n",
    "print('Model loaded.')\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "# compute the neural style loss\n",
    "# first we need to define 4 util functions\n",
    "\n",
    "# the gram matrix of an image tensor (feature-wise outer product)\n",
    "def gram_matrix(x):\n",
    "    assert K.ndim(x) == 3\n",
    "    features = K.batch_flatten(x)\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "# the \"style loss\" is designed to maintain\n",
    "# the style of the reference image in the generated image.\n",
    "# It is based on the gram matrices (which capture style) of\n",
    "# feature maps from the style reference image\n",
    "# and from the generated image\n",
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_width * img_height\n",
    "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
    "\n",
    "# an auxiliary loss function\n",
    "# designed to maintain the \"content\" of the\n",
    "# base image in the generated image\n",
    "def content_loss(base, style, combination):\n",
    "    # Changes from equation 7 (Pg# 5)\n",
    "    G = style / (base + 1e-04)\n",
    "    G_clamped = K.max(K.min(G, g_max), g_min) # Clamping values\n",
    "    Fm = base * G_clamped\n",
    "    return K.sum(K.square(combination - Fm))\n",
    "\n",
    "# the 3rd loss function, total variation loss,\n",
    "# designed to keep the generated image locally coherent\n",
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    a = K.square(x[:, :, :img_width-1, :img_height-1] - x[:, :, 1:, :img_height-1])\n",
    "    b = K.square(x[:, :, :img_width-1, :img_height-1] - x[:, :, :img_width-1, 1:])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n",
    "\n",
    "# combine these loss functions into a single scalar\n",
    "loss = K.variable(0.)\n",
    "feature_layers = ['conv3_1', 'conv4_1'] # Only conv3_1 and conv4_1 used in paper (Pg# 5)\n",
    "\n",
    "content_weight = style_weight = 0.5 # Alpha and Beta (content and style weights) are 0.5, Pg# 5\n",
    "\n",
    "# Calculating content loss\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name] # 'conv3_1' or 'conv4_1'\n",
    "    base_image_features = layer_features[0, :, :, :]\n",
    "    style_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    loss += content_weight * content_loss(base_image_features, style_features, combination_features)\n",
    "\n",
    "# Calculating style loss (in this case, painting style loss)\n",
    "temp_loss = K.variable(0.0)\n",
    "\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    temp_loss += (style_weight / len(feature_layers)) * sl\n",
    "\n",
    "gamma = 100 # Gamma weight defined as 100 in Pg# 5\n",
    "loss += temp_loss * gamma\n",
    "\n",
    "loss += total_variation_weight * total_variation_loss(combination_image)\n",
    "\n",
    "# get the gradients of the generated image wrt the loss\n",
    "grads = K.gradients(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "if type(grads) in {list, tuple}:\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image], outputs)\n",
    "def eval_loss_and_grads(x):\n",
    "    x = x.reshape((1, 3, img_width, img_height))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# this Evaluator class makes it possible\n",
    "# to compute loss and gradients in one pass\n",
    "# while retrieving them via two separate functions,\n",
    "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
    "# requires separate functions for loss and gradients,\n",
    "# but computing them separately would be inefficient.\n",
    "class Evaluator(object):\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()\n",
    "\n",
    "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "# so as to minimize the neural style loss\n",
    "\n",
    "assert args.init_image in [\"content\", \"noise\"] , \"init_image must be one of ['content', 'noise']\"\n",
    "if \"content\" in args.init_image:\n",
    "    x = preprocess_image(base_image_path, True)\n",
    "else:\n",
    "    x = np.random.uniform(0, 255, (1, 3, img_width, img_height))\n",
    "    x[0, 0, :, :] -= 103.939\n",
    "    x[0, 1, :, :] -= 116.779\n",
    "    x[0, 2, :, :] -= 123.68\n",
    "\n",
    "num_iter = args.num_iter\n",
    "for i in range(num_iter):\n",
    "    print('Start of iteration', (i+1))\n",
    "    start_time = time.time()\n",
    "\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy().reshape((3, img_width, img_height)))\n",
    "\n",
    "    if (maintain_aspect_ratio) & (not rescale_image):\n",
    "        img_ht = int(img_width * aspect_ratio)\n",
    "        print(\"Rescaling Image to (%d, %d)\" % (img_width, img_ht))\n",
    "        img = imresize(img, (img_width, img_ht), interp=args.rescale_method)\n",
    "\n",
    "    if rescale_image:\n",
    "        print(\"Rescaling Image to (%d, %d)\" % (img_WIDTH, img_HEIGHT))\n",
    "        img = imresize(img, (img_WIDTH, img_HEIGHT), interp=args.rescale_method)\n",
    "\n",
    "    fname = result_prefix + '_at_iteration_%d.png' % (i+1)\n",
    "    imsave(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i+1, end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
